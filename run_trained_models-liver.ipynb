{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "6ed4cb38",
   "metadata": {},
   "outputs": [],
   "source": [
    "#pip install easydl\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "4ce959e7",
   "metadata": {},
   "source": [
    "the cSCC dataset is 10x visium technology; the HER2+ dataset ST w/ 100 micrometer spots.\n",
    "\n",
    "thus, it is better to test with cSCC data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "053309c2-cb6d-4623-83b7-7b0d947998e6",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[easydl] tensorflow not available!\n"
     ]
    }
   ],
   "source": [
    "import torch\n",
    "import numpy as np\n",
    "import pytorch_lightning as pl\n",
    "import torchvision.transforms as tf\n",
    "from tqdm import tqdm\n",
    "from predict import *\n",
    "\n",
    "#in HIST2ST, collections.Iterable is imported via \n",
    "# from HIST2ST import * --> from transformer import* \n",
    "# --> from easydl import * --> from .pytorch import *\n",
    "# from .utils import * --> from collections import Iterable.\n",
    "# the alias Iterable has been deprecated however,\n",
    "# so you need a workaround: second answer: https://stackoverflow.com/questions/72032032/importerror-cannot-import-name-iterable-from-collections-in-python\n",
    "import collections.abc\n",
    "collections.Iterable = collections.abc.Iterable\n",
    "\n",
    "\n",
    "from HIST2ST import *\n",
    "from dataset import ViT_HER2ST, ViT_SKIN, ViT_LIVER\n",
    "from scipy.stats import pearsonr,spearmanr\n",
    "from torch.utils.data import DataLoader\n",
    "from pytorch_lightning.loggers import TensorBoardLogger\n",
    "from copy import deepcopy as dcp\n",
    "from collections import defaultdict as dfd\n",
    "from sklearn.metrics import adjusted_rand_score as ari_score\n",
    "from sklearn.metrics.cluster import normalized_mutual_info_score as nmi_score"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "feb35c52-7516-4960-a605-cc47f6c35062",
   "metadata": {},
   "source": [
    "clean memory functions from fastai22p2 notebook 11"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "af1b000f-7868-4643-a142-fb93fecd8ba4",
   "metadata": {},
   "outputs": [],
   "source": [
    "import sys\n",
    "import traceback\n",
    "import gc\n",
    "\n",
    "def clean_ipython_hist():\n",
    "    # Code in this function mainly copied from IPython source\n",
    "    if not 'get_ipython' in globals(): return\n",
    "    ip = get_ipython()\n",
    "    user_ns = ip.user_ns\n",
    "    ip.displayhook.flush()\n",
    "    pc = ip.displayhook.prompt_count + 1\n",
    "    for n in range(1, pc): user_ns.pop('_i'+repr(n),None)\n",
    "    user_ns.update(dict(_i='',_ii='',_iii=''))\n",
    "    hm = ip.history_manager\n",
    "    hm.input_hist_parsed[:] = [''] * pc\n",
    "    hm.input_hist_raw[:] = [''] * pc\n",
    "    hm._i = hm._ii = hm._iii = hm._i00 =  ''\n",
    "\n",
    "def clean_tb():\n",
    "    # h/t Piotr Czapla\n",
    "    if hasattr(sys, 'last_traceback'):\n",
    "        traceback.clear_frames(sys.last_traceback)\n",
    "        delattr(sys, 'last_traceback')\n",
    "    if hasattr(sys, 'last_type'): delattr(sys, 'last_type')\n",
    "    if hasattr(sys, 'last_value'): delattr(sys, 'last_value')\n",
    "\n",
    "def clean_mem():\n",
    "    clean_tb()\n",
    "    clean_ipython_hist()\n",
    "    gc.collect()\n",
    "    torch.cuda.empty_cache()\n",
    "\n",
    "clean_mem()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "b132bfb4-bd29-44fa-bbca-3790b0848fd4",
   "metadata": {},
   "source": [
    "# Data Loading"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "6281d8f2-e5f7-4c26-88bf-5256197b1418",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "name=[*[f'A{i}' for i in range(2,7)],*[f'B{i}' for i in range(1,7)],\n",
    "      *[f'C{i}' for i in range(1,7)],*[f'D{i}' for i in range(1,7)],\n",
    "      *[f'E{i}' for i in range(1,4)],*[f'F{i}' for i in range(1,4)],*[f'G{i}' for i in range(1,4)]]\n",
    "patients = ['P2', 'P5', 'P9', 'P10']\n",
    "reps = ['rep1', 'rep2', 'rep3']\n",
    "skinname = []\n",
    "for i in patients:\n",
    "    for j in reps:\n",
    "        skinname.append(i+'_ST_'+j)\n",
    "device='cuda'\n",
    "tag='5-7-2-8-4-16-32'\n",
    "k,p,d1,d2,d3,h,c=map(lambda x:int(x),tag.split('-'))\n",
    "dropout=0.2\n",
    "random.seed(12000)\n",
    "np.random.seed(12000)\n",
    "torch.manual_seed(12000)\n",
    "torch.cuda.manual_seed(12000)\n",
    "torch.cuda.manual_seed_all(12000)  \n",
    "torch.backends.cudnn.benchmark = False\n",
    "torch.backends.cudnn.deterministic = True"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "570acabe",
   "metadata": {},
   "source": [
    "\n",
    "# Hist2ST Prediction\n",
    "\n",
    "### To run the trained model, please select the trained model and replace the value of the variable fold with the number in the name of the selected trained model."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "0f19d5d8-6510-493b-9287-ba7215155dc1",
   "metadata": {},
   "outputs": [],
   "source": [
    "fold=0\n",
    "data='liver'\n",
    "prune='Grid' if data=='her2st' else 'NA'\n",
    "genes=171 #if data=='cscc' else 785"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "6b4a276f",
   "metadata": {},
   "source": [
    "the model was trained for the 785 HVGs in HER2+ breast cancer samples. thus, if we use default models, we will predict genes that will most likely not have anything to do with the liver. therefore, it does not make sense to use default models in the first step of the thesis.\n",
    "\n",
    "the selection for the genes has already been made before starting to train as only the selected genes will be normalized and put into self.exp_dict of the dataset"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "9efa90e4",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "['C73A1']\n",
      "Loading imgs...\n",
      "Loading metadata...\n"
     ]
    }
   ],
   "source": [
    "#load dataset with the ViT_HER2ST function if data == \"her2st\"\n",
    "#fold is the fold for the LOOCV. \n",
    "#note that the first section A1 was excluded, so fold 5 will be B1 instead of A6\n",
    "testset = pk_load(fold,'test',dataset=data,flatten=False,adj=True,ori=True,prune=prune)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "fe61e597-97ab-4130-8fc7-35f60149dc55",
   "metadata": {},
   "source": [
    "the genes were not measured in the liver dataset. now, I have to add them to the features, and add 0 for each spot"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "3a675c56",
   "metadata": {},
   "source": [
    "\"For evaluating the gene expression\n",
    "prediction accuracy, we conducted leave-one-out cross\u0002validation. Specifically, for each section, we used the left\n",
    "sections to train our model and predict gene expression\n",
    "for the section. All predictions were collected to assess\n",
    "the model performance\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "f951bf75",
   "metadata": {},
   "outputs": [],
   "source": [
    "test_loader = DataLoader(testset, batch_size=1, num_workers=0, shuffle=False)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "f0ecff91",
   "metadata": {},
   "source": [
    "the next two lines had to be commented out for the model to run on the cSCC dataset"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "id": "2c3f9af1",
   "metadata": {},
   "outputs": [],
   "source": [
    "#label=testset.label[testset.names[0]]\n",
    "#genes=785"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "af2633f6-b53e-46fd-b201-ea0442631733",
   "metadata": {},
   "source": [
    "params: \n",
    "heads = number of attention pooling heads per multi-head attention layer = 16\n",
    "\n",
    "depth2 = number of stacked multi-head attention layers = 8\n",
    "\n",
    "internally: \n",
    "\n",
    "dim = number of filters of input patch (\"we set both input and hidden dimension = 1024\") \n",
    "\n",
    "dim_head = number of filters analyzed in each of the heads = 64 default\n",
    "\n",
    "the embedding of patches goes RGB 3 -> \"?\" -> 1024 -> dim_head * head = 64 * 16 (increased number of filters for each patch now fed into the multi-head attention layer -> divide the 64 * 16 filters up equally, so that each of the 16 heads gets 64 * 16 / 16 = 64 filters (=dim_head) to perform attention on. \n",
    "\n",
    "I dont know why they chose dim_head = 64, but the positional embedding n_pos is also 64 embeddings long.\n",
    "\n",
    "however, this would fit my observations that THE DIMENSION OF THE POS EMBEDDING IS ALWAYS EQUAL TO THE DIMENSION OF THE INPUT TO THE SPECIFIC HEADS OF THE MULTIHEAD ATTENTION MODULES (-> the dimensions of both patch embedding (filter number) fed into each head as well as position embeddings are the same).\n",
    "for instance, when checking out the transformer implementations from pytorch/timm/[istar](https://github.com/mrfeldmann/istar/blob/master/vision_transformer.py) /sepal you can see that they use the dimension of 768 for the pos embedding as well as for the input dimension for each head.\n",
    "\n",
    "thus, they might have arbitrarily chosen 64 \n",
    "\n",
    "__is there a reason for why the dimensions for the embeddings are equal?__\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "id": "c8eb2627",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "n_pos 64\n",
      "dim 1024\n"
     ]
    }
   ],
   "source": [
    "model=Hist2ST(\n",
    "    depth1=d1, depth2=d2,depth3=d3,n_genes=genes, \n",
    "    kernel_size=k, patch_size=p,\n",
    "    heads=h, channel=c, dropout=0.2,\n",
    "    zinb=0.25, nb=False,\n",
    "    bake=5, lamb=0.5, \n",
    "    #n_pos = 100,\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "id": "6fbc4325",
   "metadata": {},
   "outputs": [],
   "source": [
    "#model.load_state_dict(torch.load(f'./model/{fold}-Hist2ST.ckpt'))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "id": "f712428c",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "<All keys matched successfully>"
      ]
     },
     "execution_count": 20,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "model.load_state_dict(torch.load(f'./model/{fold}_skin-Hist2ST.ckpt'))"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "7277eb17-0444-4b92-9278-2a406c3b8cbc",
   "metadata": {},
   "source": [
    "internally, the test function runs pred = model(patch, position, adj)[0] the following data from the test_loader"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "id": "b1246b72-f425-4e22-a4c9-005f84dc21ad",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "torch.Size([1, 2378, 3, 112, 112]) torch.Size([1, 2378, 2]) torch.Size([1, 2378, 171]) torch.Size([1, 2378, 2378]) torch.Size([1, 2378, 2])\n"
     ]
    }
   ],
   "source": [
    "for patch, position, exp, adj, *_, center in test_loader:\n",
    "    print(patch.shape, position.shape, exp.shape, adj.shape, center.shape)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "id": "4f8ecbb2-cbcf-49f0-9217-38c84e5d299d",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "tensor([[[ 50, 102],\n",
       "         [ 43,   9],\n",
       "         [ 47,  13],\n",
       "         ...,\n",
       "         [ 31,  77],\n",
       "         [ 58,  42],\n",
       "         [ 45,  27]]])"
      ]
     },
     "execution_count": 13,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "position"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "71f02f95-56ad-4a5a-9f10-70b22382f51d",
   "metadata": {},
   "source": [
    "then, in the forward pass of the model (HIST2ST), the position tensor is used as \"centers\", where these are embedded using self.x_embed(centers[:,:,0])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "id": "4806bc5b-c385-44c8-a3e4-022466e03e45",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(torch.Size([1, 2378]), tensor([[50, 43, 47,  ..., 31, 58, 45]]))"
      ]
     },
     "execution_count": 16,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "position[:,:,0].shape, position[:,:,0]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "id": "76cfcfb9-3169-46da-9288-2e2be7942d84",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "  0%|                                                                                             | 0/1 [00:00<?, ?it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "patches shape torch.Size([1, 2378, 3, 112, 112])\n",
      "centers shape torch.Size([1, 2378, 2])\n",
      "centers max 72\n",
      "centers min 17\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n"
     ]
    },
    {
     "ename": "IndexError",
     "evalue": "index out of range in self",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mIndexError\u001b[0m                                Traceback (most recent call last)",
      "Cell \u001b[0;32mIn[15], line 1\u001b[0m\n\u001b[0;32m----> 1\u001b[0m pred, gt \u001b[38;5;241m=\u001b[39m \u001b[43mtest\u001b[49m\u001b[43m(\u001b[49m\u001b[43mmodel\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mtest_loader\u001b[49m\u001b[43m,\u001b[49m\u001b[38;5;124;43m'\u001b[39;49m\u001b[38;5;124;43mcpu\u001b[39;49m\u001b[38;5;124;43m'\u001b[39;49m\u001b[43m)\u001b[49m\n",
      "File \u001b[0;32m/mnt/c/Users/Marvi/OneDrive/Desktop/thesis/hist2st/code/Hist2ST/predict.py:39\u001b[0m, in \u001b[0;36mtest\u001b[0;34m(model, test, device)\u001b[0m\n\u001b[1;32m     37\u001b[0m \u001b[38;5;28;01mfor\u001b[39;00m patch, position, exp, adj, \u001b[38;5;241m*\u001b[39m_, center \u001b[38;5;129;01min\u001b[39;00m tqdm(test):\n\u001b[1;32m     38\u001b[0m     patch, position, adj \u001b[38;5;241m=\u001b[39m patch\u001b[38;5;241m.\u001b[39mto(device), position\u001b[38;5;241m.\u001b[39mto(device), adj\u001b[38;5;241m.\u001b[39mto(device)\u001b[38;5;241m.\u001b[39msqueeze(\u001b[38;5;241m0\u001b[39m)\n\u001b[0;32m---> 39\u001b[0m     pred \u001b[38;5;241m=\u001b[39m \u001b[43mmodel\u001b[49m\u001b[43m(\u001b[49m\u001b[43mpatch\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mposition\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43madj\u001b[49m\u001b[43m)\u001b[49m[\u001b[38;5;241m0\u001b[39m]\n\u001b[1;32m     40\u001b[0m     preds \u001b[38;5;241m=\u001b[39m pred\u001b[38;5;241m.\u001b[39msqueeze()\u001b[38;5;241m.\u001b[39mcpu()\u001b[38;5;241m.\u001b[39mnumpy()\n\u001b[1;32m     41\u001b[0m     ct \u001b[38;5;241m=\u001b[39m center\u001b[38;5;241m.\u001b[39msqueeze()\u001b[38;5;241m.\u001b[39mcpu()\u001b[38;5;241m.\u001b[39mnumpy()\n",
      "File \u001b[0;32m~/anaconda3/lib/python3.10/site-packages/torch/nn/modules/module.py:1501\u001b[0m, in \u001b[0;36mModule._call_impl\u001b[0;34m(self, *args, **kwargs)\u001b[0m\n\u001b[1;32m   1496\u001b[0m \u001b[38;5;66;03m# If we don't have any hooks, we want to skip the rest of the logic in\u001b[39;00m\n\u001b[1;32m   1497\u001b[0m \u001b[38;5;66;03m# this function, and just call forward.\u001b[39;00m\n\u001b[1;32m   1498\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m \u001b[38;5;129;01mnot\u001b[39;00m (\u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_backward_hooks \u001b[38;5;129;01mor\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_backward_pre_hooks \u001b[38;5;129;01mor\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_forward_hooks \u001b[38;5;129;01mor\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_forward_pre_hooks\n\u001b[1;32m   1499\u001b[0m         \u001b[38;5;129;01mor\u001b[39;00m _global_backward_pre_hooks \u001b[38;5;129;01mor\u001b[39;00m _global_backward_hooks\n\u001b[1;32m   1500\u001b[0m         \u001b[38;5;129;01mor\u001b[39;00m _global_forward_hooks \u001b[38;5;129;01mor\u001b[39;00m _global_forward_pre_hooks):\n\u001b[0;32m-> 1501\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[43mforward_call\u001b[49m\u001b[43m(\u001b[49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[43margs\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[43mkwargs\u001b[49m\u001b[43m)\u001b[49m\n\u001b[1;32m   1502\u001b[0m \u001b[38;5;66;03m# Do not call functions when jit is used\u001b[39;00m\n\u001b[1;32m   1503\u001b[0m full_backward_hooks, non_full_backward_hooks \u001b[38;5;241m=\u001b[39m [], []\n",
      "File \u001b[0;32m/mnt/c/Users/Marvi/OneDrive/Desktop/thesis/hist2st/code/Hist2ST/HIST2ST.py:147\u001b[0m, in \u001b[0;36mHist2ST.forward\u001b[0;34m(self, patches, centers, adj, aug)\u001b[0m\n\u001b[1;32m    145\u001b[0m \u001b[38;5;28mprint\u001b[39m(\u001b[38;5;124mf\u001b[39m\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mcenters min \u001b[39m\u001b[38;5;132;01m{\u001b[39;00mtorch\u001b[38;5;241m.\u001b[39mmin(centers[:,:,\u001b[38;5;241m0\u001b[39m])\u001b[38;5;132;01m}\u001b[39;00m\u001b[38;5;124m\"\u001b[39m)\n\u001b[1;32m    146\u001b[0m patches \u001b[38;5;241m=\u001b[39m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mpatch_embedding(patches)\n\u001b[0;32m--> 147\u001b[0m centers_x \u001b[38;5;241m=\u001b[39m \u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mx_embed\u001b[49m\u001b[43m(\u001b[49m\u001b[43mcenters\u001b[49m\u001b[43m[\u001b[49m\u001b[43m:\u001b[49m\u001b[43m,\u001b[49m\u001b[43m:\u001b[49m\u001b[43m,\u001b[49m\u001b[38;5;241;43m0\u001b[39;49m\u001b[43m]\u001b[49m\u001b[43m)\u001b[49m\n\u001b[1;32m    148\u001b[0m centers_y \u001b[38;5;241m=\u001b[39m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39my_embed(centers[:,:,\u001b[38;5;241m1\u001b[39m])\n\u001b[1;32m    149\u001b[0m ct\u001b[38;5;241m=\u001b[39mcenters_x \u001b[38;5;241m+\u001b[39m centers_y\n",
      "File \u001b[0;32m~/anaconda3/lib/python3.10/site-packages/torch/nn/modules/module.py:1501\u001b[0m, in \u001b[0;36mModule._call_impl\u001b[0;34m(self, *args, **kwargs)\u001b[0m\n\u001b[1;32m   1496\u001b[0m \u001b[38;5;66;03m# If we don't have any hooks, we want to skip the rest of the logic in\u001b[39;00m\n\u001b[1;32m   1497\u001b[0m \u001b[38;5;66;03m# this function, and just call forward.\u001b[39;00m\n\u001b[1;32m   1498\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m \u001b[38;5;129;01mnot\u001b[39;00m (\u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_backward_hooks \u001b[38;5;129;01mor\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_backward_pre_hooks \u001b[38;5;129;01mor\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_forward_hooks \u001b[38;5;129;01mor\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_forward_pre_hooks\n\u001b[1;32m   1499\u001b[0m         \u001b[38;5;129;01mor\u001b[39;00m _global_backward_pre_hooks \u001b[38;5;129;01mor\u001b[39;00m _global_backward_hooks\n\u001b[1;32m   1500\u001b[0m         \u001b[38;5;129;01mor\u001b[39;00m _global_forward_hooks \u001b[38;5;129;01mor\u001b[39;00m _global_forward_pre_hooks):\n\u001b[0;32m-> 1501\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[43mforward_call\u001b[49m\u001b[43m(\u001b[49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[43margs\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[43mkwargs\u001b[49m\u001b[43m)\u001b[49m\n\u001b[1;32m   1502\u001b[0m \u001b[38;5;66;03m# Do not call functions when jit is used\u001b[39;00m\n\u001b[1;32m   1503\u001b[0m full_backward_hooks, non_full_backward_hooks \u001b[38;5;241m=\u001b[39m [], []\n",
      "File \u001b[0;32m~/anaconda3/lib/python3.10/site-packages/torch/nn/modules/sparse.py:162\u001b[0m, in \u001b[0;36mEmbedding.forward\u001b[0;34m(self, input)\u001b[0m\n\u001b[1;32m    161\u001b[0m \u001b[38;5;28;01mdef\u001b[39;00m \u001b[38;5;21mforward\u001b[39m(\u001b[38;5;28mself\u001b[39m, \u001b[38;5;28minput\u001b[39m: Tensor) \u001b[38;5;241m-\u001b[39m\u001b[38;5;241m>\u001b[39m Tensor:\n\u001b[0;32m--> 162\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[43mF\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43membedding\u001b[49m\u001b[43m(\u001b[49m\n\u001b[1;32m    163\u001b[0m \u001b[43m        \u001b[49m\u001b[38;5;28;43minput\u001b[39;49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mweight\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mpadding_idx\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mmax_norm\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m    164\u001b[0m \u001b[43m        \u001b[49m\u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mnorm_type\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mscale_grad_by_freq\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43msparse\u001b[49m\u001b[43m)\u001b[49m\n",
      "File \u001b[0;32m~/anaconda3/lib/python3.10/site-packages/torch/nn/functional.py:2210\u001b[0m, in \u001b[0;36membedding\u001b[0;34m(input, weight, padding_idx, max_norm, norm_type, scale_grad_by_freq, sparse)\u001b[0m\n\u001b[1;32m   2204\u001b[0m     \u001b[38;5;66;03m# Note [embedding_renorm set_grad_enabled]\u001b[39;00m\n\u001b[1;32m   2205\u001b[0m     \u001b[38;5;66;03m# XXX: equivalent to\u001b[39;00m\n\u001b[1;32m   2206\u001b[0m     \u001b[38;5;66;03m# with torch.no_grad():\u001b[39;00m\n\u001b[1;32m   2207\u001b[0m     \u001b[38;5;66;03m#   torch.embedding_renorm_\u001b[39;00m\n\u001b[1;32m   2208\u001b[0m     \u001b[38;5;66;03m# remove once script supports set_grad_enabled\u001b[39;00m\n\u001b[1;32m   2209\u001b[0m     _no_grad_embedding_renorm_(weight, \u001b[38;5;28minput\u001b[39m, max_norm, norm_type)\n\u001b[0;32m-> 2210\u001b[0m \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[43mtorch\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43membedding\u001b[49m\u001b[43m(\u001b[49m\u001b[43mweight\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;28;43minput\u001b[39;49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mpadding_idx\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mscale_grad_by_freq\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43msparse\u001b[49m\u001b[43m)\u001b[49m\n",
      "\u001b[0;31mIndexError\u001b[0m: index out of range in self"
     ]
    }
   ],
   "source": [
    "pred, gt = test(model, test_loader,'cpu')"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "4a25d61c",
   "metadata": {},
   "source": [
    "the following cell shows what data is used inside the test function.\n",
    "I dont get what the difference between center and position is yet though"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "id": "520c7787",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "patch: torch.Size([1, 2378, 3, 112, 112])\n",
      "position: torch.Size([1, 2378, 2]) are the x,y centers for the forward pass. \n",
      "Expression: torch.Size([1, 2378, 171])\n",
      "adj = adjacency matrix torch.Size([1, 2378, 2378])\n",
      "center: torch.Size([1, 2378, 2])\n"
     ]
    }
   ],
   "source": [
    "for patch, position,exp, adj, *_, center in test_loader:\n",
    "    print(f\"patch: {patch.shape}\")\n",
    "    print(f\"position: {position.shape} are the x,y centers for the forward pass. \")\n",
    "    print(f\"Expression: {exp.shape}\")\n",
    "    print(f\"adj = adjacency matrix {adj.shape}\")\n",
    "    print(f\"center: {center.shape}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "id": "0fdb3e26",
   "metadata": {},
   "outputs": [
    {
     "ename": "NameError",
     "evalue": "name 'pred' is not defined",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mNameError\u001b[0m                                 Traceback (most recent call last)",
      "Cell \u001b[0;32mIn[10], line 1\u001b[0m\n\u001b[0;32m----> 1\u001b[0m \u001b[43mpred\u001b[49m, gt\n",
      "\u001b[0;31mNameError\u001b[0m: name 'pred' is not defined"
     ]
    }
   ],
   "source": [
    "pred, gt\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "d2aefc5b",
   "metadata": {},
   "source": [
    "521 spots (?) x 171 genes"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "id": "786b8c3c",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(521, 2)"
      ]
     },
     "execution_count": 15,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "pred.obsm[\"spatial\"].shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "id": "9c423df4",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([[4581., 8002.],\n",
       "       [4586., 8809.],\n",
       "       [4766., 7408.],\n",
       "       ...,\n",
       "       [9634., 8815.],\n",
       "       [9628., 9224.],\n",
       "       [9623., 9620.]], dtype=float32)"
      ]
     },
     "execution_count": 16,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# spatial are the center (ct) locations of the spots\n",
    "pred.obsm[\"spatial\"]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "id": "a99c1ae0",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(521, 171)"
      ]
     },
     "execution_count": 17,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "pred.X.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "id": "b73d5390",
   "metadata": {},
   "outputs": [],
   "source": [
    "#get_R??"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "id": "11707f64",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "2"
      ]
     },
     "execution_count": 19,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "#returns tuple of all array(r values), array(all pvalues)\n",
    "len(get_R(pred,gt))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "id": "4266cce3-6bc7-4f5b-81d5-d03d3ae089c4",
   "metadata": {
    "pycharm": {
     "name": "#%%\n"
    }
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Pearson Correlation: 0.10740173624584474\n"
     ]
    }
   ],
   "source": [
    "R=get_R(pred,gt)[0]\n",
    "print('Pearson Correlation:',np.nanmean(R))\n",
    "\n",
    "\n",
    "# clus,ARI=cluster(pred,label)\n",
    "# print('ARI:',ARI)\n"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.11"
  },
  "pycharm": {
   "stem_cell": {
    "cell_type": "raw",
    "metadata": {
     "collapsed": false
    },
    "source": []
   }
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
